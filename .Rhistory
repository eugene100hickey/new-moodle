legend.direction = "horizontal")
ggplot() +
geom_sf(data = streets$osm_lines,
color = "#151515",
size = .2) +
geom_sf(data = iso_df,
aes(colour = as.factor(value),
geometry = geometry),
fill = "#060606",
size = .2,
alpha = .8) +
scale_colour_manual(values = rev(colpal),
labels = seq(10,100,10),
guide = guide_legend(override.aes = list(fill = rev(colpal), alpha = 1),
nrow = 1,
keywidth = 1.5,
keyheight = 0.3,
title.position = "top",
label.position = "bottom",
label.hjust = 0.5)) +
coord_sf(xlim = custom_wandsworth[1,],
ylim = custom_wandsworth[2,],
expand = FALSE)  +
with_outer_glow(annotate(geom = "text", label = "Walking the streets of Battersea",
x = -6.24, y = 53.31, size = 7.5, hjust = 0.5, colour = colpal[10], family = "mono"),
colour = colpal[4], sigma = 10, expand = 10) +
with_outer_glow(annotate(geom = "text", label = "How far can one walk from Clapham Junction in 100 minutes?",
x = -6.24, y = 53.32, size = 4, hjust = 0.5, colour = colpal[10], family = "mono"),
colour = colpal[4], sigma = 10, expand = 7) +
with_outer_glow(annotate(geom = "text", label = "@jamie_bio | source = © openrouteservice.org by HeiGIT | Map data © OpenStreetMap contributors",
x = -6.26, y = 53.33, size = 1.5, hjust = 0.5, colour = colpal[10], family = "mono"),
colour = colpal[4], sigma = 10, expand = 4) +
theme_void() +
theme(plot.background = element_rect(fill = "#060606"),
panel.background = element_rect(fill = "#060606"),
# legend.text = with_outer_glow(element_text(colour = colpal[6],
#                                            family = "mono"),
#                               colour = colpal[4],
#                               sigma = 2,
#                               expand = 3),
legend.title = element_blank(),
legend.position=c(0.5, 0.85),
legend.justification = "bottom",
legend.direction = "horizontal")
# https://r.iresmi.net/posts/2025/oil_spill/
library(glue)
library(dplyr)
library(sf)
library(janitor)
library(readxl)
library(leaflet)
library(leaflet.providers)
library(leaflet.extras)
# https://figshare.com/ndownloader/files/55233773
if (!file.exists("enhanced_global_oil_spill_data_240711.xlsx")) {
download.file("https://figshare.com/ndownloader/files/55233773",
"enhanced_global_oil_spill_data_240711.xlsx")
}
oil <- read_xlsx("enhanced_global_oil_spill_data_240711.xlsx",
sheet = "Oil spill incidents",
.name_repair = make_clean_names) |>
mutate(release_m3 = if_else(max_ptl_release_gallons == -1,
NA_real_,
round(0.00454609 * max_ptl_release_gallons))) |>
st_as_sf(coords = c("lon", "lat"), crs = "EPSG:4326")
oil <- read_xlsx("https://figshare.com/ndownloader/files/55233773/enhanced_global_oil_spill_data_240711.xlsx",
sheet = "Oil spill incidents",
.name_repair = make_clean_names) |>
mutate(release_m3 = if_else(max_ptl_release_gallons == -1,
NA_real_,
round(0.00454609 * max_ptl_release_gallons))) |>
st_as_sf(coords = c("lon", "lat"), crs = "EPSG:4326")
oil <- read_xlsx("https://figshare.com/ndownloader/files/55233773",
sheet = "Oil spill incidents",
.name_repair = make_clean_names) |>
mutate(release_m3 = if_else(max_ptl_release_gallons == -1,
NA_real_,
round(0.00454609 * max_ptl_release_gallons))) |>
st_as_sf(coords = c("lon", "lat"), crs = "EPSG:4326")
library(tidyverse)
library(words)
opts <- "[zipsare]"
i <- 12
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
i <- 10
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
i <- 9
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
library(tidyverse)
library(matlab)
begin <- 10003
end <- 20000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 19003
end <- 20000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset(".a.ti")
lambda <- 0.154051
theta <- c(16, 18.5, 26.5, 32, 33)
d <- lambda / (2 * sin(theta/180*pi))
d
hkl <- c(sqrt(3), 2, sqrt(8), sqrt(11), sqrt(12))
d*hkl
theta = 10
d <- lambda / (2 * sin(theta/180*pi))
d
d*sqrt(2)
library(tidyverse)
library(words)
opts <- "[shipong]"
i <- 14
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
i <- 13
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
i <- 12
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
i <- 11
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
i <- 10
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
i <- 9
z <- words |> dplyr::filter(word_length == i) |> pull(word)
str_subset(z, pattern = glue::glue(str_dup("{opts}", i)))
here::here()
library(tidyverse)
library(gt)
library(readxl)
my_file <- here::here("lectures", "registers", "first-year-list.xlsx")
sheets <- excel_sheets(my_file)
z <- read_excel(my_file, sheet = sheets[1]) |> # 1 for bio, 2 for pharma
janitor::clean_names()
z <- read_excel(my_file, sheet = sheets[2]) |> # 1 for bio, 2 for pharma
janitor::clean_names()
View(z)
library(tidyverse)
theta_2 <- c(27.3, 31.6, 45.3, 53.85, 56.4)
d <- 0.154051 / (2 * sin(theta_2 / 2 * pi / 180))
hkl <- c(3, 4, 8, 11, 12)
d*hkl
d/hkl
d*sqrt(hkl)
d
theta_2 <- c(26.7, 31, 44.4, 52.7, 55.2)
d <- 0.154051 / (2 * sin(theta_2 / 2 * pi / 180))
d
d*sqrt(hkl)
theta_2 <- c(26.5, 30.8, 46, 54, 57, 67, 76, 84)
d <- 0.154051 / (2 * sin(theta_2 / 2 * pi / 180))
hkl <- c(3, 4, 8, 11, 12, 16, 19, 20, 24)
d*sqrt(hkl)
hkl <- c(3, 4, 8, 11, 12, 16, 19, 20)
d*sqrt(hkl)
d
0.56/0.193
.Last.value^2
theta_2 <- c(26.5, 30.8, 45.5, 54, 57, 67, 76, 84)
d <- 0.154051 / (2 * sin(theta_2 / 2 * pi / 180))
d
0.56/0.199
.Last.value^2
install.packages("gex")
scales::show_col(c("#C864b4", "#500AaA")
)
install.packages("ggpercentogram")
install.packages(c("filtro", "important"))
install.packages("gex")
#install.packages("remotes")  # if not yet installed
remotes::install_github("matt-dray/gex")
library(filtro)
?filtro::score_cor_spearman
library(tidyverse)
library(matlab)
begin <- 30001
end <- 40000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 30071
end <- 40000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(tidyverse)
library(matlab)
begin <- 20003
end <- 30000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 26083
end <- 27000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
3499/547.7/6
here::here()
42*0.7
library(tidyverse)
library(matlab)
begin <- 10009
end <- 20000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 10071
end <- 20000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset("bo.ge")
z |> str_subset(".o.ge")
z |> str_subset("dou.a")
z |> str_subset(".od.a")
z |> str_subset(".o..h")
z |> str_subset(".o.[-g]h")
z |> str_subset(".o.[^g]h")
z |> str_subset(".o.[^gct]h")
z |> str_subset(".iane")
z |> str_subset(".orth")
z |> str_subset(".etel")
z |> str_subset(".ru.g")
library(tidyverse)
library(matlab)
begin <- 30007
end <- 40000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 63507
end <- 63600
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 60537
end <- 70000
my_step <- 1000
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
install.packages("healthiar")
library(healthiar)
exdat_pm
View(exdat_pm)
attribute_health(
erf_shape = "log_linear",
rr_central = exdat_pm$relative_risk,
rr_increment = 10,
exp_central = exdat_pm$mean_concentration,
cutoff_central = exdat_pm$cut_off_value,
bhd_central = exdat_pm$incidence
)
z <- .Last.value
z[[1]]
z[[1]] |> View()
begin <- 20041
end <- 30000
my_step <- 1000
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 20841
end <- 30000
my_step <- 1000
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset("e.ade")
z |> str_subset(".orde")
z |> str_subset("ro.de")
z |> str_subset(".ova.")
z |> str_subset("snea.")
# install.packages("remotes")
remotes::install_github("hypertidy/cmemsarco")
# install.packages("remotes")
remotes::install_github("hypertidy/cmemsarco")
library(cmemsarco)
data(cmems_catalog_data)
catalog <- cmems_catalog_data
library(cmemsarco)
data(cmems_catalog_data)
catalog <- cmems_catalog_data
View(cmems_catalog_data)
catalog$native_url[12]
catalog$native_url[12] |> url()
catalog$native_url[12] |> browseURL()
library(tidyverse)
# Filter to what you need
sla <- catalog |>
dplyr::filter(product_id == "SEALEVEL_GLO_PHY_L4_MY_008_047") |>
cmems_latest()  # latest version per dataset
# Get the GDAL-ready DSN
dsn <- sla$timeChunked_gdal[1]
dsn
#> [1] "ZARR:\"/vsicurl/https://s3.waw3-1.cloudferro.com/mdl-arco-time-045/arco/SEALEVEL_GLO_PHY_L4_MY_008_047/cmems_obs-sl_glo_phy-ssh_my_allsat-l4-duacs-0.125deg_P1D_202411/timeChunked.zarr\""
View(sla)
sla |> browseURL()
sla
dsn |> browseURL()
dsn
## first band of "adt" var (using Classic syntax for ZARR driver)
dsn_2d <- sprintf("%s:/adt:0", dsn)
ds <- new(gdalraster::GDALRaster, dsn_2d)
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset("man.e")
z |> str_subset("tro.e")
z |> str_subset("ta.er")
library(constants)
constants::codata
?constants::codata
z <- codata
data("codata")
codata
library(constants)
install_unit("c2^2/GeV^2")
constants::codata
constants::install_unit("^")
library(units)
units::install_unit("^")
library(constants)
units::install_unit("c2^2/GeV^2")
library(constants)
valid_udunits_prefixes()
?install_unit
units::install_unit("^")
valid_udunits_prefixes()
valid_udunits()
View(.Last.value)
library(constants)
install.packages("constants")
library(constants)
install.packages("constants")
library(constants)
install.packages("errors")
install.packages("quantities")
library(constants)
z <- codata
View(z)
e <- z$value[z$symbol == "e"]
mp <- z$value[z$symbol == "mp"]
hbar <- z$value[z$symbol == "hbar"]
e*hbar / (2*mp)
1/mp
me <- z$value[z$symbol == "me"]
e*hbar / (2*me)
library(constants)
z=codata
View(z)
z[213,]
library(tidyverse)
library(matlab)
begin <- 50003
end <- 90000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 95003
end <- 96000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset("s.erd")
library(tidyverse)
library(matlab)
begin <- 50001
end <- 99000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 50001
end <- 60000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
# Enable repository from terminological
options(repos = c(
terminological = 'https://terminological.r-universe.dev',
CRAN = 'https://cloud.r-project.org'))
# Download and install dtrackr in R
install.packages('dtrackr')
# a pipeline parameter
cutOff = 3
# the pipeline
dataset = iris %>%
track() %>%
status() %>%
group_by(Species) %>%
status(
short = p_count_if(Sepal.Width<cutOff),
long= p_count_if(Sepal.Width>=cutOff),
.messages=c("consisting of {short} short sepal <{cutOff}","and {long} long sepal >={cutOff}")
)  %>%
exclude_all(
Petal.Width<0.3 ~ "excluding {.excluded} with narrow petals",
Petal.Width == max(Petal.Width) ~ "and {.excluded} outlier"
) %>%
comment("test message") %>%
status(.messages = "{.count} of type {Species}") %>%
ungroup() %>%
status(.messages = "{.count} together with cutOff {cutOff}")
library(dtrackr)
# a pipeline parameter
cutOff = 3
# the pipeline
dataset = iris %>%
track() %>%
status() %>%
group_by(Species) %>%
status(
short = p_count_if(Sepal.Width<cutOff),
long= p_count_if(Sepal.Width>=cutOff),
.messages=c("consisting of {short} short sepal <{cutOff}","and {long} long sepal >={cutOff}")
)  %>%
exclude_all(
Petal.Width<0.3 ~ "excluding {.excluded} with narrow petals",
Petal.Width == max(Petal.Width) ~ "and {.excluded} outlier"
) %>%
comment("test message") %>%
status(.messages = "{.count} of type {Species}") %>%
ungroup() %>%
status(.messages = "{.count} together with cutOff {cutOff}")
dataset |> flowchart()
library(constants)
z <- codata
View(z)
mp <- z$value[z$symbol == "mp"]
mn <- z$value[z$symbol == "mn"]
mn/mp
(mn-mp)/mp
(mn-mp)/mp*100
library(gt)
?tab_header
?cols_label
?fmt_fraction
library(tidyverse)
library(matlab)
begin <- 50001
end <- 60000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 90019
end <- 100000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 80019
end <- 90000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset("hart.")
z |> str_subset("aste.")
z |> str_subset("ster.")
z |> str_subset("n.res")
z |> str_subset("mauv.")
z |> str_subset(".erns")
suncalc::getSunlightTimes(date = Sys.Date(), lat = 53.32, lon = -6.2378)
suncalc::getSunlightTimes(date = Sys.Date(), lat = 53.32, lon = -6.2378)$sunrise
suncalc::getSunlightTimes(date = Sys.Date()+30, lat = 53.32, lon = -6.2378)$sunrise
suncalc::getSunlightTimes(date = Sys.Date()+35, lat = 53.32, lon = -6.2378)$sunrise
library(tidyverse)
library(matlab)
begin <- 43007
end <- 44000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 43009
end <- 44000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset(".asil")
,37*18
.37*18
z |> str_subset(".a.en")
begin <- 20001
end <- 30000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
z |> str_subset("se.ed")
z <- words |> dplyr::filter(word_length == 6) |> pull(word)
z |> str_subset("ad.are")
z |> str_subset(".o.a")
z <- words |> dplyr::filter(word_length == 4) |> pull(word)
z |> str_subset(".o.a")
