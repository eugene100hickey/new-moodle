xml_title <-  ".lister-item-header a"
xml_genre <- ".genre"
xml_rating <- ".ratings-imdb-rating strong"
w <- read_html(new_url)
title_data_html <- html_nodes(w, xml_title)
genre_data_html <- html_nodes(w, xml_genre)
rating_data_html <- html_nodes(w, xml_rating)
codes <- html_attr(html_nodes(w, "a"), "href") |>
as_tibble() |>
filter(str_detect(value, "/title/tt"),
str_detect(value, "ref_=adv_li_tt")) |>
mutate(value = str_remove(value, "/title/tt"),
value = str_remove(value, "ref_=adv_li_tt"),
value = str_remove(value, "//?"),
value = str_sub(value, start = 1, end = nchar(value)-1)) |>
distinct()
title <- html_text(title_data_html)
genre <- html_text(genre_data_html) |>
str_remove_all("\n") |>
str_squish()
rating <- html_text(rating_data_html)|>
str_remove_all("\n") |>
str_squish()
z <- tibble(title = title,
genre = genre,
rating = as.numeric(rating),
code = codes$value)
}
(all_movies <- map_df(0:3, movie_ratings) |>
filter(rating == my_rating))
index <- 1
cast_url <- glue::glue("https://www.imdb.com/title/tt{all_movies$code[index]}/fullcredits/?ref_=tt_ql_cl")
xml_cast <- ".primary_photo+ td a"
w <- read_html(cast_url)
cast_data_html <- html_nodes(w, xml_cast)
(cast <- html_text(cast_data_html) |>
str_remove("\n") |>
str_squish())
cast1 <- cast
library(tidyverse)
library(matlab)
begin <- 40003
end <-41000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
start <- 0
year <- 2017
my_rating <- 7.3
movie_ratings <- function(start = 20) {
start <- start*50
new_url <- glue::glue("https://www.imdb.com/search/title/?title_type=feature&year={year}-01-01,{year}-12-31&start={start}")
xml_title <-  ".lister-item-header a"
xml_genre <- ".genre"
xml_rating <- ".ratings-imdb-rating strong"
w <- read_html(new_url)
title_data_html <- html_nodes(w, xml_title)
genre_data_html <- html_nodes(w, xml_genre)
rating_data_html <- html_nodes(w, xml_rating)
codes <- html_attr(html_nodes(w, "a"), "href") |>
as_tibble() |>
filter(str_detect(value, "/title/tt"),
str_detect(value, "ref_=adv_li_tt")) |>
mutate(value = str_remove(value, "/title/tt"),
value = str_remove(value, "ref_=adv_li_tt"),
value = str_remove(value, "//?"),
value = str_sub(value, start = 1, end = nchar(value)-1)) |>
distinct()
title <- html_text(title_data_html)
genre <- html_text(genre_data_html) |>
str_remove_all("\n") |>
str_squish()
rating <- html_text(rating_data_html)|>
str_remove_all("\n") |>
str_squish()
z <- tibble(title = title,
genre = genre,
rating = as.numeric(rating),
code = codes$value)
}
(all_movies <- map_df(0:3, movie_ratings) |>
filter(rating == my_rating))
index <- 5
cast_url <- glue::glue("https://www.imdb.com/title/tt{all_movies$code[index]}/fullcredits/?ref_=tt_ql_cl")
xml_cast <- ".primary_photo+ td a"
w <- read_html(cast_url)
cast_data_html <- html_nodes(w, xml_cast)
(cast <- html_text(cast_data_html) |>
str_remove("\n") |>
str_squish())
cast1 <- cast
year <- 2005
my_rating <- 8
movie_ratings <- function(start = 20) {
start <- start*50
new_url <- glue::glue("https://www.imdb.com/search/title/?title_type=feature&year={year}-01-01,{year}-12-31&start={start}")
xml_title <-  ".lister-item-header a"
xml_genre <- ".genre"
xml_rating <- ".ratings-imdb-rating strong"
w <- read_html(new_url)
title_data_html <- html_nodes(w, xml_title)
genre_data_html <- html_nodes(w, xml_genre)
rating_data_html <- html_nodes(w, xml_rating)
codes <- html_attr(html_nodes(w, "a"), "href") |>
as_tibble() |>
filter(str_detect(value, "/title/tt"),
str_detect(value, "ref_=adv_li_tt")) |>
mutate(value = str_remove(value, "/title/tt"),
value = str_remove(value, "ref_=adv_li_tt"),
value = str_remove(value, "//?"),
value = str_sub(value, start = 1, end = nchar(value)-1)) |>
distinct()
title <- html_text(title_data_html)
genre <- html_text(genre_data_html) |>
str_remove_all("\n") |>
str_squish()
rating <- html_text(rating_data_html)|>
str_remove_all("\n") |>
str_squish()
z <- tibble(title = title,
genre = genre,
rating = as.numeric(rating),
code = codes$value)
}
(all_movies <- map_df(0:3, movie_ratings) |>
filter(rating == my_rating))
(all_movies <- map_df(0:3, movie_ratings) |>
filter(str_detect(genre, "Family"),
#str_detect(genre, "Crime"),
str_detect(genre, "Family")))
(all_movies <- map_df(0:3, movie_ratings) |>
filter(rating == my_rating))
index <- 1
cast_url <- glue::glue("https://www.imdb.com/title/tt{all_movies$code[index]}/fullcredits/?ref_=tt_ql_cl")
xml_cast <- ".primary_photo+ td a"
w <- read_html(cast_url)
cast_data_html <- html_nodes(w, xml_cast)
(cast <- html_text(cast_data_html) |>
str_remove("\n") |>
str_squish())
cast[cast %in% cast1]
year <- 2014
my_rating <- 8
movie_ratings <- function(start = 20) {
start <- start*50
new_url <- glue::glue("https://www.imdb.com/search/title/?title_type=feature&year={year}-01-01,{year}-12-31&start={start}")
xml_title <-  ".lister-item-header a"
xml_genre <- ".genre"
xml_rating <- ".ratings-imdb-rating strong"
w <- read_html(new_url)
title_data_html <- html_nodes(w, xml_title)
genre_data_html <- html_nodes(w, xml_genre)
rating_data_html <- html_nodes(w, xml_rating)
codes <- html_attr(html_nodes(w, "a"), "href") |>
as_tibble() |>
filter(str_detect(value, "/title/tt"),
str_detect(value, "ref_=adv_li_tt")) |>
mutate(value = str_remove(value, "/title/tt"),
value = str_remove(value, "ref_=adv_li_tt"),
value = str_remove(value, "//?"),
value = str_sub(value, start = 1, end = nchar(value)-1)) |>
distinct()
title <- html_text(title_data_html)
genre <- html_text(genre_data_html) |>
str_remove_all("\n") |>
str_squish()
rating <- html_text(rating_data_html)|>
str_remove_all("\n") |>
str_squish()
z <- tibble(title = title,
genre = genre,
rating = as.numeric(rating),
code = codes$value)
}
(all_movies <- map_df(0:3, movie_ratings) |>
filter(str_detect(genre, "Action"),
str_detect(genre, "Adventure"),
str_detect(genre, "Sci-Fi")))
library(words)
z <- words |>
filter(word_length == 5)
z |> filter(str_detect(word, "ri.it"))
z |> filter(str_detect(word, ".ri.t"))
begin <- 50007
end <-100000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1 & between(numbers %% 10000, 00, 1000)]
begin <- 50009
end <- 51000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
1.69*.59
year <- 2013
my_rating <- 7.8
movie_ratings <- function(start = 20) {
start <- start*50
new_url <- glue::glue("https://www.imdb.com/search/title/?title_type=feature&year={year}-01-01,{year}-12-31&start={start}")
xml_title <-  ".lister-item-header a"
xml_genre <- ".genre"
xml_rating <- ".ratings-imdb-rating strong"
w <- read_html(new_url)
title_data_html <- html_nodes(w, xml_title)
genre_data_html <- html_nodes(w, xml_genre)
rating_data_html <- html_nodes(w, xml_rating)
codes <- html_attr(html_nodes(w, "a"), "href") |>
as_tibble() |>
filter(str_detect(value, "/title/tt"),
str_detect(value, "ref_=adv_li_tt")) |>
mutate(value = str_remove(value, "/title/tt"),
value = str_remove(value, "ref_=adv_li_tt"),
value = str_remove(value, "//?"),
value = str_sub(value, start = 1, end = nchar(value)-1)) |>
distinct()
title <- html_text(title_data_html)
genre <- html_text(genre_data_html) |>
str_remove_all("\n") |>
str_squish()
rating <- html_text(rating_data_html)|>
str_remove_all("\n") |>
str_squish()
z <- tibble(title = title,
genre = genre,
rating = as.numeric(rating),
code = codes$value)
}
(all_movies <- map_df(0:3, movie_ratings) |>
filter(rating == my_rating))
index <- 3
cast_url <- glue::glue("https://www.imdb.com/title/tt{all_movies$code[index]}/fullcredits/?ref_=tt_ql_cl")
xml_cast <- ".primary_photo+ td a"
w <- read_html(cast_url)
cast_data_html <- html_nodes(w, xml_cast)
(cast <- html_text(cast_data_html) |>
str_remove("\n") |>
str_squish())
cast1 <- cast
year <- 2019
my_rating <- 8.4
movie_ratings <- function(start = 20) {
start <- start*50
new_url <- glue::glue("https://www.imdb.com/search/title/?title_type=feature&year={year}-01-01,{year}-12-31&start={start}")
xml_title <-  ".lister-item-header a"
xml_genre <- ".genre"
xml_rating <- ".ratings-imdb-rating strong"
w <- read_html(new_url)
title_data_html <- html_nodes(w, xml_title)
genre_data_html <- html_nodes(w, xml_genre)
rating_data_html <- html_nodes(w, xml_rating)
codes <- html_attr(html_nodes(w, "a"), "href") |>
as_tibble() |>
filter(str_detect(value, "/title/tt"),
str_detect(value, "ref_=adv_li_tt")) |>
mutate(value = str_remove(value, "/title/tt"),
value = str_remove(value, "ref_=adv_li_tt"),
value = str_remove(value, "//?"),
value = str_sub(value, start = 1, end = nchar(value)-1)) |>
distinct()
title <- html_text(title_data_html)
genre <- html_text(genre_data_html) |>
str_remove_all("\n") |>
str_squish()
rating <- html_text(rating_data_html)|>
str_remove_all("\n") |>
str_squish()
z <- tibble(title = title,
genre = genre,
rating = as.numeric(rating),
code = codes$value)
}
(all_movies <- map_df(0:3, movie_ratings) |>
filter(rating == my_rating))
index <- 1
cast_url <- glue::glue("https://www.imdb.com/title/tt{all_movies$code[index]}/fullcredits/?ref_=tt_ql_cl")
xml_cast <- ".primary_photo+ td a"
w <- read_html(cast_url)
cast_data_html <- html_nodes(w, xml_cast)
(cast <- html_text(cast_data_html) |>
str_remove("\n") |>
str_squish())
cast[cast %in% cast1]
acos(0.630)*180/pi
acos(24/25)*180/pi
library(tidyverse)
library(words)
z <- words |>
filter(word_length == 5)
z |> filter(str_detect(word, "any.."))
z |> filter(str_detect(word, ".y..."))
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
end <- 100000
begin <- 30013
library(tidyverse)
library(matlab)
library(words)
begin <- 30013
end <- 100000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 30193
end <- 100000
my_step <- 1000
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 60193
end <- 90000
my_step <- 1000
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
log(30/40)
1/.Last.value
120*4190
.Last.value/34.8
12*4190*20
44/ln(50/6)
44/log(50/6)
1005600/20.8
library(tidyverse)
library(words)
z <- words |>
filter(word_length == 5)
z |> filter(str_detect(word, "..do."))
z |> filter(str_detect(word, "....o"))
library(arthistory)
arthistory::worksgardner |> names()
install.packages("COVID19")
library(COVID19)
?COVID19::covid19
View(covid19)
data(package = "COVID19")
x <- covid19(c("Italy", "US"), level = 3)
View(x)
library(tidyverse)
library(matlab)
begin <- 21007
end <- 21100
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 20001
end <- 30000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(opencv)
z <- ocv_read("../../../../../Downloads/Flyer Academic Writing & Publication module 2023 24 CQ F.pdf")
z <- ocv_read("../../../../../Downloads/Flyer Academic Writing & Publication module 2023 24 CQ F.pdf")
z <- ocv_read("../../../../../Downloads/flyer.png")
ocv_qr_detect(z)
library(tidyverse)
library(matlab)
begin <-13007
end <- 13100
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <-10307
end <- 20000
my_step <- 1000
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(tidyverse)
library(matlab)
begin <- 40007
end <- 50000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 60007
end <- 90000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1 & between(numbers %% 10000, 6400, 6500)]
library(words)
z <- words |>
dplyr::filter(word_length == 5)
z |> filter(str_detect(word, "le.ee"))
z |> filter(str_detect(word, ".asty"))
z |> filter(str_detect(word, ".al.p"))
z |> filter(str_detect(word, ".al.h"))
library(tidyvderse)
library(tidyverse)
readRDS(file = "data/poverty.RDS")
usethis::create_github_token()
gitcreds::gitcreds_set()
gitcreds::gitcreds_set("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")
library(tidyverse)
library(matlab)
begin <- 42001
end <- 42100
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset(".rasp")
29*31
library(rentrez)
?rentrez::entrez_search
entrez_search(db="nuccore", term = "GSE788")
library(GEOquery)
z <- getGEO("GSE788")
z
z1 <- z[[1]]
z1
methods(class = class(z1))
exprs(z1)
exprs(z1) |> class()
z2 <- exprs(z1)
mean(z2[, "GSM9024"])
usethis::create_github_token()
gitcreds::gitcreds_set()
library(tidyverse)
library(matlab)
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset("..pal")
library(learnr)
?question
library(exams)
library(exams)
world_sf <- sf::st_as_sf(rworldmap::getMap(resolution = "low"))
lat <- c(seq(from=-90,to=90,by=0.25)) ## creates a sequence -90 to 90 by 0.25
lon <- c(rep(180,length(lat)),rep(-180,length(lat))) # creates a sequence of 180 and -180 longitudes
oceans.df <- data.frame("lon"=lon, "lat"=c(lat,lat)) ## combines the point in a data frame
oceans.sf <- st_as_sf(oceans.df,coords = c("lon","lat"), crs=4326) %>%
st_union() %>% # combines the points into a MULTIPOINT
st_convex_hull() # gets the outline of the points
library(tidyverse)
library(flipbookr)
library(ggtext)
library(worldfootballR)
library(gt)
library(sf)
library(rworldmap)
library(lwgeom)
world_sf <- sf::st_as_sf(rworldmap::getMap(resolution = "low"))
lat <- c(seq(from=-90,to=90,by=0.25)) ## creates a sequence -90 to 90 by 0.25
lon <- c(rep(180,length(lat)),rep(-180,length(lat))) # creates a sequence of 180 and -180 longitudes
oceans.df <- data.frame("lon"=lon, "lat"=c(lat,lat)) ## combines the point in a data frame
oceans.sf <- st_as_sf(oceans.df,coords = c("lon","lat"), crs=4326) %>%
st_union() %>% # combines the points into a MULTIPOINT
st_convex_hull() # gets the outline of the points
oceans_moll.sf <- st_as_sf(oceans.df,coords = c("lon","lat"), crs=4326) %>%
st_transform(crs="+proj=moll") %>% ##
st_union() %>% # combines the points into a MULTIPOINT
st_convex_hull() # gets the outline of the points
my_cols <- c("#008000", "#1aff1a", "#802000", "#24478f", "#e6e600", "#7733ff", "#ff80aa")
ggplot() +
geom_sf(data=oceans_moll.sf, fill="#cce6ff") +
geom_sf(data=world_sf |> st_transform(crs="+proj=moll"),
aes(fill = NAME), show.legend = FALSE) + #BREAK
scale_fill_manual(values = rep(paletteer_d("MexBrewer::Naturaleza", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("palettetown::crobat", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("lisa::JosefAlbers", n=5), 50)) + #ROTATE
scale_fill_manual(values = rep(my_cols, 35)) +
theme_void() + annotation_scale(location = "bl", width_hint = 0.5) + annotation_north_arrow(location = "bl", which_north = "true", pad_x = unit(0.75, "in"), pad_y = unit(0.5, "in"), style = north_arrow_fancy_orienteering) #BREAK
library(paletteer)
ggplot() +
geom_sf(data=oceans_moll.sf, fill="#cce6ff") +
geom_sf(data=world_sf |> st_transform(crs="+proj=moll"),
aes(fill = NAME), show.legend = FALSE) + #BREAK
scale_fill_manual(values = rep(paletteer_d("MexBrewer::Naturaleza", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("palettetown::crobat", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("lisa::JosefAlbers", n=5), 50)) + #ROTATE
scale_fill_manual(values = rep(my_cols, 35)) +
theme_void() + annotation_scale(location = "bl", width_hint = 0.5) + annotation_north_arrow(location = "bl", which_north = "true", pad_x = unit(0.75, "in"), pad_y = unit(0.5, "in"), style = north_arrow_fancy_orienteering) #BREAK
library(ggspatial)
ggplot() +
geom_sf(data=oceans_moll.sf, fill="#cce6ff") +
geom_sf(data=world_sf |> st_transform(crs="+proj=moll"),
aes(fill = NAME), show.legend = FALSE) + #BREAK
scale_fill_manual(values = rep(paletteer_d("MexBrewer::Naturaleza", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("palettetown::crobat", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("lisa::JosefAlbers", n=5), 50)) + #ROTATE
scale_fill_manual(values = rep(my_cols, 35)) +
theme_void() + annotation_scale(location = "bl", width_hint = 0.5) + annotation_north_arrow(location = "bl", which_north = "true", pad_x = unit(0.75, "in"), pad_y = unit(0.5, "in"), style = north_arrow_fancy_orienteering) #BREAK
ggplot() +
geom_sf(data=oceans_moll.sf, fill="#cce6ff") +
geom_sf(data=world_sf |> st_transform(crs="+proj=moll"),
aes(fill = NAME), show.legend = FALSE) + #BREAK
scale_fill_manual(values = rep(paletteer_d("MexBrewer::Naturaleza", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("palettetown::crobat", n=7), 35)) + #ROTATE
scale_fill_manual(values = rep(paletteer_d("lisa::JosefAlbers", n=5), 50)) + #ROTATE
scale_fill_manual(values = rep(my_cols, 35)) +
theme_void() +
#annotation_scale(location = "bl", width_hint = 0.5) +
annotation_north_arrow(location = "bl", which_north = "true", pad_x = unit(0.75, "in"), pad_y = unit(0.5, "in"), style = north_arrow_fancy_orienteering)
library(tidyverse)
library(matlab)
begin <- 21003
end <- 22000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 31123
end <- 99000
my_step <- 1000
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 52013
end <- 53000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |> dplyr::filter(word_length == 5) |> pull(word)
z |> str_subset("a.oid")
